{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create images DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE IMAGES DATAFRAME FROM ORDERS DATAFRAME AND DATA FROM ETI - BY IMAGE LIST\n",
    "\n",
    "images_df = pd.DataFrame()\n",
    "images_df[\"Order ID\"] = orders_df[\"Order ID\"]\n",
    "images_df[\"images_list\"] = orders_df[\"Order ID\"].apply(env.eti_api.get_image_list_by_orderid)\n",
    "\n",
    "images_df = pd.concat([orders_df.set_index('Order ID'),\n",
    "                       images_df.set_index('Order ID')], axis=1, join='inner').reset_index()\n",
    "\n",
    "images_df = images_df.explode('images_list').rename(columns={'images_list': 'Image_ID'}).reset_index(drop=True)\n",
    "\n",
    "# images_data = images_df[\"Image_ID\"].apply(env.eti_api.get_image_list_by_orderid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD IMAGES DATA BY ORDER ID FROM ETI (without splitting list of orders)\n",
    "\n",
    "import tqdm.notebook as tq\n",
    "import warnings\n",
    "example_images_df = env.eti_api.get_images_data_by_orderid(orders_list[0])['images']\n",
    "images_df = pd.DataFrame(columns=example_images_df[0].keys())\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "    for order in tq.tqdm(orders_list, leave=False):\n",
    "        order_df = pd.DataFrame(env.eti_api.get_images_data_by_orderid(order)['images'])\n",
    "        images_df = pd.concat([images_df, order_df], axis='rows', ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.eti_api.get_categories_hierarchy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW RANDOM IMAGE FROM THE DATAFRAME\n",
    "\n",
    "example_image_id = random.sample(list(top_weeds_df['imageID']), 1)[0]\n",
    "image_data = top_weeds_df[top_weeds_df['imageID'] == example_image_id].reset_index()\n",
    "image_num_tags = image_data.at[0, 'num_weed_tags']\n",
    "image_crop_name = image_data.at[0, 'cropName']\n",
    "\n",
    "im_path = env.download_image(example_image_id)\n",
    "image = io.imread(im_path)\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.title(f\"Image ID: {example_image_id}\\nCrop Type: {image_crop_name}, Weed Tags: {image_num_tags}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_im_path = env.download_image(matching_wide_image_id)\n",
    "wide_image = io.imread(wide_im_path)\n",
    "\n",
    "plt.imshow(wide_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD WIDE IMAGE_ID TO EACH ZOOM IMAGE\n",
    "example_wide_image = env.eti_api.get_matching_wide_images([7275584])\n",
    "# wide_images = env.eti_api.get_matching_wide_images(list(top_weeds_df['imageID']))\n",
    "wide_im_path = env.download_image(example_wide_image[0])\n",
    "wide_image = io.imread(wide_im_path)\n",
    "\n",
    "plt.imshow(wide_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD WIDE IMAGE_ID TO EACH ZOOM IMAGE\n",
    "example_wide_image = env.eti_api.get_matching_wide_images([7275584])\n",
    "# wide_images = env.eti_api.get_matching_wide_images(list(top_weeds_df['imageID']))\n",
    "wide_im_path = env.download_image(example_wide_image[0])\n",
    "wide_image = io.imread(wide_im_path)\n",
    "\n",
    "plt.imshow(wide_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIEW AND FIND INFORMATION ABOUT NUMBER OF WEED TAGS IN THE IMAGES\n",
    "images_with_weeds_df = images_df[images_df['num_weed_tags']]\n",
    "print(len(images_with_weeds_df))\n",
    "plt.hist(images_with_weeds_df['num_weed_tags'], bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(filtered_images_df['cameraAngle'], bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(images_df['cameraAngle'], bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images_with_the_most_weeds_tags['num_weed_tags']\n",
    "plt.hist(top_weeds_soy['num_weed_tags'], bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_orderid = random.sample(orders_list, 1)[0]\n",
    "\n",
    "im_list = env.eti_api.get_image_list_by_orderid(example_orderid, [2])\n",
    "example_image_id = random.sample(im_list, 1)[0]\n",
    "\n",
    "im_path = env.download_image(example_image_id)\n",
    "image = io.imread(im_path)\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_hierarchy = env.eti_api.get_categories_hierarchy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(categories_hierarchy)):\n",
    "    print(f\"{i}, category: {categories_hierarchy[i]['id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD CATEGORIES NAME AND TYPES TO IMAGES DATAFRAME\n",
    "\n",
    "def create_cat_dict(cat_list):\n",
    "    cat_dict_types = {}\n",
    "    cat_dict_names = {}\n",
    "    for l in cat_list:\n",
    "        if 'type' in l:\n",
    "            cat_dict_types[l['id']] = l['type']\n",
    "        else:\n",
    "            cat_dict_types[l['id']] = 'NoType'\n",
    "        if 'name' in l:\n",
    "            cat_dict_names[l['id']] = l['name']\n",
    "        else:\n",
    "            cat_dict_names[l['id']] = 'NoName'\n",
    "    return cat_dict_types, cat_dict_names\n",
    "\n",
    "\n",
    "\n",
    "def get_weed_subcategory_name_by_subcategory_id(types_ids_list):\n",
    "    types_ids_list = eval(types_ids_list)\n",
    "    print(types_ids_list)\n",
    "    cat_dict_types, cat_dict_names = create_cat_dict(categories_hierarchy[9]['subCategories'])\n",
    "    names_list = []\n",
    "    types_list = []\n",
    "    print(len(types_ids_list))\n",
    "    for i in range(len(types_ids_list)):\n",
    "        print(cat_dict_names[types_ids_list[i]])\n",
    "        names_list.append(cat_dict_names[types_ids_list[i]])\n",
    "        types_list.append(cat_dict_types[types_ids_list[i]])\n",
    "\n",
    "    \n",
    "    \n",
    "    # weed_subcategories = categories_hierarchy[9]['subCategories']\n",
    "    # names_list = []\n",
    "    # for i in range(len(types_ids_list)):\n",
    "    #     for j in range(len(weed_subcategories)):\n",
    "    #         if weed_subcategories[j]['id'] == types_ids_list[i]:\n",
    "    #             names_list.append(weed_subcategories[j]['name'])\n",
    "\n",
    "    # if len(names_list) != len(types_ids_list):\n",
    "        # raise Exception(\"names_list and types_ids_list lengths are different\")\n",
    "    return names_list\n",
    "\n",
    "images_df[images_df['weed_types_ids_list'].apply(get_weed_subcategory_name_by_subcategory_id)]\n",
    "# print(images_df[images_df['weed_types_ids_list'].apply(get_weed_subcategory_name_by_subcategory_id)])\n",
    "# images_df['weed_types_list'] = images_df[images_df['weed_types_ids_list'].apply(get_weed_subcategory_name_by_subcategory_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df = pd.read_csv(\"/mnt/disks/datasets/wide_images/images_df_new_1.csv\")\n",
    "unique_weed_types = np.unique(images_df['weed_types_dict'].explode(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXCLUDED IMAGES FOR CREATING FINAL_DF:\n",
    "# FROM interesting_weed_df: [8980681, 8980665, 7076176, 8980677, 7073428, 8980673, 7077207, 7073971, 8980669]\n",
    "# FROM small_num_of_tags_df_soy : [8190898, 10384238, 6513168, 9182595, 8016877, 8415772, 6767859, 8733629, 9120611, 8730740, 6467322]\n",
    "# FROM small_num_of_tags_df_corn :\n",
    "# excluded_image_ids.extend([8980681, 8980665, 7076176, 8980677, 7073428, 8980673, 7077207, 7073971, 8980669])\n",
    "# excluded_image_ids.extend([8190898, 10384238, 6513168, 9182595, 8016877, 8415772, 6767859, 8733629, 9120611, 8730740, 6467322])\n",
    "# excluded_image_ids.extend([7037805, 6245305, 7836752, 7836449, 7899418, 7836202, 7043002])\n",
    "# excluded_image_ids.extend([6325835, 6325719, 6325835])\n",
    "# excluded_image_ids.extend([5729837, 8724366, 5729837, 5828866, 7652376])\n",
    "# excluded_image_ids.extend([5682996, 5397485, 8718398, 5396859, 8718440, 5161751])\n",
    "# excluded_image_ids.extend([5682996, 5161751, 6264631, 8718440, 8718398])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 0.017749786376953125 GB\n",
      "Available RAM: 2.6995697021484375 GB\n"
     ]
    }
   ],
   "source": [
    "# CHECK RAM USAGE\n",
    "\n",
    "import psutil\n",
    "\n",
    "# Get the system's memory information\n",
    "memory_info = psutil.virtual_memory()\n",
    "# Access the available RAM in bytes\n",
    "available_ram = memory_info.available\n",
    "# Convert bytes to gigabytes (GB)\n",
    "available_ram_gb = available_ram / (1024 ** 3)\n",
    "\n",
    "# Get the memory usage for the current process (kernel)\n",
    "process = psutil.Process()\n",
    "memory_info = process.memory_info()\n",
    "memory_usage_mb = memory_info.rss / 1024 / 1024\n",
    "memory_usage_gb = memory_usage_mb / 1024\n",
    "\n",
    "print(f\"Memory usage: {memory_usage_gb} GB\")\n",
    "\n",
    "print(f\"Available RAM: {available_ram_gb} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE - ADDING ORDERS DATA TO IMAGES DF\n",
    "\n",
    "orders_df = pd.DataFrame({'orders' : [1,2,3,4], 'pass_num' : [1,1,2,2]})\n",
    "images_df = pd.DataFrame({'orders' : [1, 1, 1, 2, 2, 3, 4, 4, 4], 'im_num' : [111, 121, 122, 123, 333, 444,555, 333, 999]})\n",
    "\n",
    "merged_df = images_df.merge(orders_df, on='orders')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from late flights data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTER IMAGES DATAFRAME\n",
    "from datetime import datetime\n",
    "\n",
    "im_df = im_df[(im_df['cameraAngle'] > -95) & (im_df['cameraAngle'] < -85)]\n",
    "im_df = im_df[im_df['deleted'] != True]\n",
    "\n",
    "# im_df['weed_types_ids_list'] = im_df['weed_types_ids_list'].apply(eval)\n",
    "# im_df['uploadDate_time'] = im_df['uploadDate'].apply(datetime.fromtimestamp)\n",
    "# im_df['uploadDate_date'] = im_df['uploadDate_time'].apply(lambda x: x.to_pydatetime().date())\n",
    "\n",
    "# im_df.columns\n",
    "len(im_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "im_df['pass_num_new'] = None\n",
    "im_df['pass_num_new'] = np.where(im_df['fieldID'].isin(early_flights_field_ids), 1, im_df['pass_num_new'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW IMAGES FROM THE DATAFRAME\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# df_to_show = df_for_resolution_lim_checkup[20:].reset_index(drop=True)\n",
    "df_to_show = example_images.reset_index(drop=True)\n",
    "\n",
    "for i in range(len(df_to_show)):\n",
    "    example_image_id = df_to_show['imageID'][i]\n",
    "    # SHOW IMAGES\n",
    "    print(f\"Zoom image id: {example_image_id}\")\n",
    "    image_data = df_to_show[df_to_show['imageID'] == example_image_id].reset_index(drop=True)\n",
    "\n",
    "    # # image_data = df_to_show[df_to_show['imageID'] == example_image_id]\n",
    "    # # matching_wide_image_id = int(image_data.at[0, 'wideImageID'])\n",
    "    # # print(f\"Wide image id: {matching_wide_image_id}\")\n",
    "    # image_num_tags = image_data.at[0, 'num_weed_tags']\n",
    "    # image_num_manual_tags = image_data.at[0, 'weed_manualTagsCount']\n",
    "    # image_num_inference_tags = image_data.at[0, 'weed_inferenceTagsCount']\n",
    "    pass_num = image_data.at[0, 'pass_num']\n",
    "    # image_crop_name = image_data.at[0, 'cropName']\n",
    "    # upload_date = image_data.at[0, 'uploadDate_date']\n",
    "    # weed_types = image_data.at[0, 'weed_types_ids_list']\n",
    "    # # weed_types = eval(image_data.at[0, 'weed_types_ids_list'])\n",
    "    # weed_types = list(map(cat_dict_names.get, weed_types))\n",
    "\n",
    "\n",
    "    im_path = env.download_image(int(example_image_id))\n",
    "    image = io.imread(im_path)\n",
    "\n",
    "    # wide_im_path = env.download_image(int(matching_wide_image_id))\n",
    "    # wide_image = io.imread(wide_im_path)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1)\n",
    "    axes.imshow(image, extent=[0, image.shape[1], 0, image.shape[0]])\n",
    "    # axes[1].imshow(wide_image, extent=[0, wide_image.shape[1], 0, wide_image.shape[0]])\n",
    "\n",
    "\n",
    "    axes.set_xticks([])\n",
    "    axes.set_yticks([])\n",
    "    fig.set_size_inches(20, 10)\n",
    "    plt.suptitle(f\"pass num: {pass_num}\")\n",
    "    # plt.suptitle(f\"Crop Type: {image_crop_name}\\nZoom Image ID: {example_image_id}\\nuploadDate: {upload_date}\\nNum Weed Tags: {image_num_tags}\\nManual tags: {image_num_manual_tags}, Inference tags: {image_num_inference_tags}\\nWeed types: {weed_types}\")\n",
    "    # plt.suptitle(f\"Crop Type: {image_crop_name}\\nZoom Image ID: {example_image_id}, Wide Image ID: {matching_wide_image_id}\\nuploadDate: {upload_date}\\nNum Weed Tags: {image_num_tags}\\nManual tags: {image_num_manual_tags}, Inference tags: {image_num_inference_tags}\\nWeed types: {weed_types}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_df['pass_num'] = [int(eval(im_df['Pass #'][i])['value']) for i in range(len(im_df))]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create grid json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_json_path = \"data/dataloop_jsons/6415975.json\"\n",
    "example_json_path = 'data/dataloop_jsons/example_json_from_itayg.json'\n",
    "with open(example_json_path) as file:\n",
    "    example_data = json.load(file)\n",
    "\n",
    "# example_polygon_coordinates = example_data['annotations'][0]['coordinates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_random_boxes_coords(items_df, image_shape, num_boxes=10, grid_shape=(507, 434)):\n",
    "    grid_coords = get_grid_coords(image_shape)\n",
    "\n",
    "\n",
    "    random_boxes = grid_coords.sample(n=10)\n",
    "\n",
    "    top_left_random_boxes = np.random.choice(top_left_list, size=num_boxes, replace=False)\n",
    "\n",
    "    bottom_right_random_boxes = top_left_random_boxes + np.array(grid_shape)\n",
    "\n",
    "    items_df['top_left'] = np.array(list(map(tuple, top_left_random_boxes)))\n",
    "    items_df['bottom_right'] = np.array(list(map(tuple, bottom_right_random_boxes)))\n",
    "\n",
    "    # np.array(list(zip(top_random_selection, left_random_selection)))\n",
    "    items_df['boxes_coords'] = {'top_left': np.array(list(map(tuple, top_left_random_boxes))),\n",
    "                                'bottom_right': np.array(list(map(tuple, bottom_right_random_boxes)))}\n",
    "    return items_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # example_image_id_from_dataset = items_df['name'][0]\n",
    "    # example_im_path = env.download_image(int(example_image_id_from_dataset))\n",
    "    # example_image = io.imread(example_im_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD TO DATAFRAME IMAGES FROM TTT\n",
    "ttt_images_paths = glob.glob(os.path.join(\"images_to_dataloop_ttt/wide_ttt\", \"*.jpg\"))\n",
    "ttt_images_ids = [int(os.path.basename(p).replace(\".jpg\", \"\")) for p in ttt_images_paths]\n",
    "df_existing_images = weeds_df[weeds_df['imageID'].isin(ttt_images_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZOOM IMAGES THAT DOESNT HAVE WIDE \n",
    "\n",
    "problematic_images_zoom = images_data_new[images_data_new['wideImageID'].isna()]['imageID']\n",
    "wide_checkup = env.eti_api.get_matching_wide_images(list(problematic_images_zoom))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resolution reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLUR IMAGE - BLOCK REDUCE\n",
    "\n",
    "resolution_options = [7, 8, 9, 10]  # mm / pixel\n",
    "\n",
    "\n",
    "random_image_id = int(os.path.basename(np.random.choice(jsons_paths_list)).replace(\".json\", \"\"))\n",
    "random_image_data = images_data[images_data['imageID'] == random_image_id]\n",
    "\n",
    "im_path = env.download_image(random_image_id)\n",
    "original_image = io.imread(im_path)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(24, 8), tight_layout=True, constrained_layout=True)\n",
    "axs = axs.flatten()\n",
    "for i, ax in enumerate(axs):\n",
    "    processed_image = skimage.measure.block_reduce(original_image, (resolution_options[i],resolution_options[i],1), np.mean).astype(np.uint8)\n",
    "    processed_image = resize(processed_image, (original_image.shape[0], original_image.shape[1]), mode='constant', anti_aliasing=False)\n",
    "    ax.imshow(processed_image)\n",
    "    ax.set_title(f\"Block size: {resolution_options[i]}\")\n",
    "    # del upscaled_image\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESOLUTION CALCULATION - TRY. NOT GOOD\n",
    "\n",
    "\n",
    "def get_x_y_px(resolution, new_resolution, fp_x_m, fp_y_m):\n",
    "    x_px = int(resolution/new_resolution) * fp_x_m\n",
    "    y_px = int(resolution/new_resolution) * fp_y_m\n",
    "    return x_px, y_px\n",
    "\n",
    "\n",
    "def get_image_resolution(height, focal_length):\n",
    "    fp_x_m = (height / focal_length) * CCD_X # m\n",
    "    fp_y_m = (height / focal_length) * CCD_Y # m\n",
    "    # total_ground_area = fp_x_m * fp_y_m # m^2\n",
    "    resolution = 0.5*(fp_x_m/IMAGE_X_PX + fp_y_m/IMAGE_Y_PX)*1000 # mm/px\n",
    "    return resolution, fp_x_m, fp_y_m\n",
    "\n",
    "\n",
    "# random_image_id = int(os.path.basename(np.random.choice(jsons_paths_list)).replace(\".json\", \"\"))\n",
    "random_image_id = 9568380\n",
    "random_image_data = images_data[images_data['imageID'] == random_image_id]\n",
    "\n",
    "im_path = env.download_image(random_image_id)\n",
    "original_image = io.imread(im_path)\n",
    "\n",
    "flights_heights_options = np.arange(20, 55, 5)\n",
    "\n",
    "for h in flights_heights_options:\n",
    "    focal_length = random_image_data['focalLength'].values[0]\n",
    "    flight_height = random_image_data['heightAboveGround'].values[0]\n",
    "    image_resolution, fp_x_m, fp_y_m = get_image_resolution(flight_height, focal_length)\n",
    "    new_image_resolution, new_fp_x_m, new_fp_y_m = get_image_resolution(h, focal_length)\n",
    "    print(f\"image_resolution: {image_resolution:.2f}, image_new_resolution:{new_image_resolution:.2f}\")\n",
    "    print(f\"new_fp_x_m: {new_fp_x_m:.2f},new_fp_y_m: {new_fp_y_m:.2f}\")\n",
    "    image_x_px_new, image_y_px_new = get_x_y_px(image_resolution, new_image_resolution)\n",
    "    print(f\"new image shape: ({image_x_px_new, image_y_px_new})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW IMAGES DIFFERENT RESOLUTIONS\n",
    "\n",
    "random_image_id = int(os.path.basename(np.random.choice(jsons_paths_list)).replace(\".json\", \"\"))\n",
    "random_image_data = images_data[images_data['imageID'] == random_image_id]\n",
    "\n",
    "im_path = env.download_image(random_image_id)\n",
    "original_image = io.imread(im_path)\n",
    "\n",
    "num_images = len(resolutions_dict)\n",
    "num_rows = (num_images + 1) // 2  # Calculate the number of rows needed\n",
    "\n",
    "fig, axs = plt.subplots(num_rows, 2, figsize=(8, 8))  # Create subplots\n",
    "\n",
    "for i, height in enumerate(resolutions_dict.keys()):\n",
    "    processed_image = resize(original_image, (resolutions_dict[height][0], resolutions_dict[height][0], 3), anti_aliasing=True)\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    ax = axs[row, col]\n",
    "    ax.imshow(processed_image)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f\"Height: {height}\")\n",
    "\n",
    "# If the number of images is odd, remove the last subplot\n",
    "if num_images % 2 != 0:\n",
    "    axs[num_rows - 1, 1].axis('off')\n",
    "    fig.delaxes(axs[num_rows - 1, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLUR IMAGE BY RESOLUTION\n",
    "\n",
    "random_image_id = int(os.path.basename(np.random.choice(jsons_paths_list)).replace(\".json\", \"\"))\n",
    "random_image_data = images_data[images_data['imageID'] == random_image_id]\n",
    "\n",
    "im_path = env.download_image(random_image_id)\n",
    "original_image = io.imread(im_path)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(24, 8), tight_layout=True, constrained_layout=True)\n",
    "axs = axs.flatten()\n",
    "for i, ax in enumerate(axs):\n",
    "    processed_image = resize(original_image, (resolutions_dict[50][0], resolutions_dict[50][0], 3), anti_aliasing=True)\n",
    "    processed_image = resize(processed_image, (original_image.shape[0], original_image.shape[1]), mode='constant', anti_aliasing=False)\n",
    "    # processed_image = skimage.measure.block_reduce(original_image, (resolution_options[i],resolution_options[i],1), np.mean).astype(np.uint8)\n",
    "    # processed_image = resize(processed_image, (original_image.shape[0], original_image.shape[1]), mode='constant', anti_aliasing=False)\n",
    "    ax.imshow(processed_image)\n",
    "    ax.set_title(f\"Block size: {resolution_options[i]}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISPLAY ONE POLYGON ON DIFFERENT RESOLUTION IMAGES\n",
    "\n",
    "example_image_id = random_image_id\n",
    "# example_image_id = 7843185\n",
    "# example_image_id = 6415975\n",
    "CHOSEN_TAG = 1\n",
    "\n",
    "# example_json_path = \"data/dataloop_jsons/6415975.json\"\n",
    "example_json_path = f\"data/dataloop/annotations_anafa_2023_06_23_resolution_lim_dataset_1_v0/json/{example_image_id}.json\"\n",
    "images_resolutions_paths_list = glob.glob(os.path.join(resized_images_folder, f\"{example_image_id}*.jpg\"))\n",
    "images_resolutions_paths_list = [images_resolutions_paths_list[0], images_resolutions_paths_list[-1]]\n",
    "\n",
    "\n",
    "with open(example_json_path) as file:\n",
    "    example_data = json.load(file)\n",
    "\n",
    "example_polygon_coordinates = example_data['annotations'][0]['coordinates']\n",
    "# im_path = env.download_image(int(example_image_id))\n",
    "\n",
    "x_values = [coord['x'] for coord in example_data['annotations'][CHOSEN_TAG]['coordinates'][0]]\n",
    "y_values = [coord['y'] for coord in example_data['annotations'][CHOSEN_TAG]['coordinates'][0]]\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "num_images = len(images_resolutions_paths_list)\n",
    "num_rows = num_images // 2  # Divide and round up\n",
    "num_cols = min(num_images, 2)\n",
    "\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(10, 10))\n",
    "\n",
    "axs = axs.flatten()\n",
    "for i, ax in enumerate(axs):\n",
    "\n",
    "    image = io.imread(images_resolutions_paths_list[i])\n",
    "    polygon = patches.Polygon(list(zip(x_values, y_values)), closed=True, fill=None, edgecolor='aquamarine')\n",
    "\n",
    "    ax.imshow(image)\n",
    "    ax.add_patch(polygon)\n",
    "\n",
    "    ax.set_xlim(min(x_values)-100, max(x_values)+100)\n",
    "    ax.set_ylim(min(y_values)-100, max(y_values)+100)\n",
    "\n",
    "    subtitle = images_resolutions_paths_list[i].replace(f\"{example_image_id}_\", \"\")\n",
    "    ax.set_title(f\"image: {os.path.basename(subtitle)}\")\n",
    "\n",
    "fig.suptitle(f\"Image ID: {example_image_id}\", y=0.8)\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISPLAY ALL DL POLYGONS ON THE IMAGE\n",
    "\n",
    "# example_image_id = 6044767\n",
    "example_image_id = 6415975\n",
    "\n",
    "# example_json_path = \"data/dataloop_jsons/6415975.json\"\n",
    "example_json_path = f\"data/dataloop/annotations_anafa_2023_06_23_resolution_lim_dataset_1_v0/json/{example_image_id}.json\"\n",
    "\n",
    "with open(example_json_path) as file:\n",
    "    example_data = json.load(file)\n",
    "\n",
    "example_polygon_coordinates = example_data['annotations'][0]['coordinates']\n",
    "im_path = env.download_image(int(example_image_id))\n",
    "image = io.imread(im_path)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "num_images = len(example_data['annotations'])\n",
    "num_rows = num_images // 2  # Divide and round up\n",
    "num_cols = min(num_images, 2)\n",
    "\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(10, 10))\n",
    "\n",
    "axs = axs.flatten()\n",
    "for i, ax in enumerate(axs):\n",
    "\n",
    "    x_values = [coord['x'] for coord in example_data['annotations'][i]['coordinates'][0]]\n",
    "    y_values = [coord['y'] for coord in example_data['annotations'][i]['coordinates'][0]]\n",
    "    polygon = patches.Polygon(list(zip(x_values, y_values)), closed=True, fill=None, edgecolor='aquamarine')\n",
    "\n",
    "    ax.imshow(image)\n",
    "    ax.add_patch(polygon)\n",
    "\n",
    "    ax.set_xlim(min(x_values)-100, max(x_values)+100)\n",
    "    ax.set_ylim(min(y_values)-100, max(y_values)+100)\n",
    "\n",
    "    ax.set_title(f\"tag: {example_data['annotations'][i]['label']}\")\n",
    "\n",
    "fig.suptitle(f\"Image ID: {example_image_id}\")\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLUR IMAGE BY RESOLUTION\n",
    "\n",
    "random_image_id = int(os.path.basename(np.random.choice(jsons_paths_list)).replace(\".json\", \"\"))\n",
    "random_image_data = images_data[images_data['imageID'] == random_image_id]\n",
    "\n",
    "im_path = env.download_image(random_image_id)\n",
    "original_image = io.imread(im_path)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(24, 8), tight_layout=True, constrained_layout=True)\n",
    "axs = axs.flatten()\n",
    "for i, ax in enumerate(axs):\n",
    "    processed_image = resize(original_image, (resolutions_dict[50][0], resolutions_dict[50][0], 3), anti_aliasing=True)\n",
    "    processed_image = resize(processed_image, (original_image.shape[0], original_image.shape[1]), mode='constant', anti_aliasing=False)\n",
    "    # processed_image = skimage.measure.block_reduce(original_image, (resolution_options[i],resolution_options[i],1), np.mean).astype(np.uint8)\n",
    "    # processed_image = resize(processed_image, (original_image.shape[0], original_image.shape[1]), mode='constant', anti_aliasing=False)\n",
    "    ax.imshow(processed_image)\n",
    "    ax.set_title(f\"Block size: {resolution_options[i]}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_image_id = example_image_data['wideImageID']\n",
    "wide_im_path = env.download_image(int(wide_image_id))\n",
    "wide_image = io.imread(wide_im_path)\n",
    "wide_image_data = env.eti_api.get_images_data([wide_image_id])\n",
    "\n",
    "wide_image_shape = wide_image.shape[0], wide_image.shape[1]\n",
    "wide_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(24, 8), tight_layout=True, constrained_layout=True)\n",
    "axs = axs.flatten()\n",
    "for i, ax in enumerate(axs):\n",
    "    processed_image = resize(original_image, (resolutions_dict[50][0], resolutions_dict[50][0], 3), anti_aliasing=True)\n",
    "    processed_image = resize(processed_image, (original_image.shape[0], original_image.shape[1]), mode='constant', anti_aliasing=False)\n",
    "    # processed_image = skimage.measure.block_reduce(original_image, (resolution_options[i],resolution_options[i],1), np.mean).astype(np.uint8)\n",
    "    # processed_image = resize(processed_image, (original_image.shape[0], original_image.shape[1]), mode='constant', anti_aliasing=False)\n",
    "    ax.imshow(processed_image)\n",
    "    ax.set_title(f\"Block size: {resolution_options[i]}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESIZE IMAGES AND SAVE - FROM IMAGES SIZE LIST\n",
    "\n",
    "resized_images_folder = os.path.join(\"images\", \"resized_images\")\n",
    "os.makedirs(resized_images_folder, exist_ok=True)\n",
    "\n",
    "# random_image_id = int(os.path.basename(np.random.choice(jsons_paths_list)).replace(\".json\", \"\"))\n",
    "# random_image_id = 6415975\n",
    "# random_image_data = images_data[images_data['imageID'] == random_image_id]\n",
    "\n",
    "random_image_id = example_image_id\n",
    "\n",
    "im_path = env.download_image(random_image_id)\n",
    "original_image = io.imread(im_path)\n",
    "\n",
    "for i in range(len(ax_0)):\n",
    "    processed_image_name = f\"{random_image_id}_{i}_try4.jpg\"\n",
    "    processed_image_path = os.path.join(resized_images_folder, processed_image_name)\n",
    "    processed_image = resize(original_image, (ax_1[i], ax_0[i], 3), anti_aliasing=True)\n",
    "    processed_image = resize(processed_image, (original_image.shape[0], original_image.shape[1]), mode='constant', anti_aliasing=False)\n",
    "\n",
    "    io.imsave(processed_image_path, processed_image)\n",
    "    processed_image = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESIZE IMAGES AND SAVE - FROM RESOLUTION DICT\n",
    "\n",
    "resized_images_folder = os.path.join(\"images\", \"resized_images\")\n",
    "os.makedirs(resized_images_folder, exist_ok=True)\n",
    "\n",
    "random_image_id = int(os.path.basename(np.random.choice(jsons_paths_list)).replace(\".json\", \"\"))\n",
    "# random_image_id = 6415975\n",
    "random_image_data = images_data[images_data['imageID'] == random_image_id]\n",
    "\n",
    "im_path = env.download_image(random_image_id)\n",
    "original_image = io.imread(im_path)\n",
    "\n",
    "for i, height in enumerate(resolutions_dict.keys()):\n",
    "    processed_image_name = f\"{random_image_id}_h_{height}_try.jpg\"\n",
    "    processed_image_path = os.path.join(resized_images_folder, processed_image_name)\n",
    "    processed_image = resize(original_image, (resolutions_dict[height][1], resolutions_dict[height][0], 3), anti_aliasing=True)\n",
    "    processed_image = resize(processed_image, (original_image.shape[0], original_image.shape[1]), mode='constant', anti_aliasing=False)\n",
    "\n",
    "    io.imsave(processed_image_path, processed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_steps = 5\n",
    "# step_size = (wide_image_resolution - zoom_image_resolution) / (num_steps - 1)\n",
    "# resolutions_list = np.arange(zoom_image_resolution, wide_image_resolution + 2*step_size, step_size)\n",
    "\n",
    "# resolutions_list = resolution_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE RESOLUTION DICTIONARY BY ZOOM IMAGE SIZE\n",
    "\n",
    "# GET WIDE IMAGE SHAPE\n",
    "# example_image_id = 5246509\n",
    "# example_image_id = 6415975\n",
    "zoom_im_path = env.download_image(int(example_image_id))\n",
    "\n",
    "zoom_image = io.imread(zoom_im_path)\n",
    "wide_im_id = env.eti_api.get_matching_wide_images([example_image_id])[0]\n",
    "wide_im_path = env.download_image(wide_im_id)\n",
    "wide_image = io.imread(wide_im_path)\n",
    "wide_image_shape = wide_image.shape[:-1]\n",
    "\n",
    "# grid_shape = (wide_image_shape[1]//7, wide_image_shape[0]//8)\n",
    "num_steps = 5\n",
    "\n",
    "step_size_0 = (wide_image_shape[0] - wide_image_shape[0]//7) / (num_steps - 1)\n",
    "step_size_1 = (wide_image_shape[1] - wide_image_shape[1]//8) / (num_steps - 1)\n",
    "\n",
    "ax_0 = np.arange(wide_image_shape[0]//7, wide_image_shape[0], step_size_0).astype(int)\n",
    "ax_1 = np.arange(wide_image_shape[1]//8, wide_image_shape[1], step_size_1).astype(int)\n",
    "\n",
    "del zoom_image, wide_image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
