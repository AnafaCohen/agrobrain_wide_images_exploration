{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create images DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE IMAGES DATAFRAME FROM ORDERS DATAFRAME AND DATA FROM ETI - BY IMAGE LIST\n",
    "\n",
    "images_df = pd.DataFrame()\n",
    "images_df[\"Order ID\"] = orders_df[\"Order ID\"]\n",
    "images_df[\"images_list\"] = orders_df[\"Order ID\"].apply(env.eti_api.get_image_list_by_orderid)\n",
    "\n",
    "images_df = pd.concat([orders_df.set_index('Order ID'),\n",
    "                       images_df.set_index('Order ID')], axis=1, join='inner').reset_index()\n",
    "\n",
    "images_df = images_df.explode('images_list').rename(columns={'images_list': 'Image_ID'}).reset_index(drop=True)\n",
    "\n",
    "# images_data = images_df[\"Image_ID\"].apply(env.eti_api.get_image_list_by_orderid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD IMAGES DATA BY ORDER ID FROM ETI (without splitting list of orders)\n",
    "\n",
    "import tqdm.notebook as tq\n",
    "import warnings\n",
    "example_images_df = env.eti_api.get_images_data_by_orderid(orders_list[0])['images']\n",
    "images_df = pd.DataFrame(columns=example_images_df[0].keys())\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "    for order in tq.tqdm(orders_list, leave=False):\n",
    "        order_df = pd.DataFrame(env.eti_api.get_images_data_by_orderid(order)['images'])\n",
    "        images_df = pd.concat([images_df, order_df], axis='rows', ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.eti_api.get_categories_hierarchy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW RANDOM IMAGE FROM THE DATAFRAME\n",
    "\n",
    "example_image_id = random.sample(list(top_weeds_df['imageID']), 1)[0]\n",
    "image_data = top_weeds_df[top_weeds_df['imageID'] == example_image_id].reset_index()\n",
    "image_num_tags = image_data.at[0, 'num_weed_tags']\n",
    "image_crop_name = image_data.at[0, 'cropName']\n",
    "\n",
    "im_path = env.download_image(example_image_id)\n",
    "image = io.imread(im_path)\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.title(f\"Image ID: {example_image_id}\\nCrop Type: {image_crop_name}, Weed Tags: {image_num_tags}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_im_path = env.download_image(matching_wide_image_id)\n",
    "wide_image = io.imread(wide_im_path)\n",
    "\n",
    "plt.imshow(wide_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD WIDE IMAGE_ID TO EACH ZOOM IMAGE\n",
    "example_wide_image = env.eti_api.get_matching_wide_images([7275584])\n",
    "# wide_images = env.eti_api.get_matching_wide_images(list(top_weeds_df['imageID']))\n",
    "wide_im_path = env.download_image(example_wide_image[0])\n",
    "wide_image = io.imread(wide_im_path)\n",
    "\n",
    "plt.imshow(wide_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD WIDE IMAGE_ID TO EACH ZOOM IMAGE\n",
    "example_wide_image = env.eti_api.get_matching_wide_images([7275584])\n",
    "# wide_images = env.eti_api.get_matching_wide_images(list(top_weeds_df['imageID']))\n",
    "wide_im_path = env.download_image(example_wide_image[0])\n",
    "wide_image = io.imread(wide_im_path)\n",
    "\n",
    "plt.imshow(wide_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIEW AND FIND INFORMATION ABOUT NUMBER OF WEED TAGS IN THE IMAGES\n",
    "images_with_weeds_df = images_df[images_df['num_weed_tags']]\n",
    "print(len(images_with_weeds_df))\n",
    "plt.hist(images_with_weeds_df['num_weed_tags'], bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(filtered_images_df['cameraAngle'], bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(images_df['cameraAngle'], bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images_with_the_most_weeds_tags['num_weed_tags']\n",
    "plt.hist(top_weeds_soy['num_weed_tags'], bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_orderid = random.sample(orders_list, 1)[0]\n",
    "\n",
    "im_list = env.eti_api.get_image_list_by_orderid(example_orderid, [2])\n",
    "example_image_id = random.sample(im_list, 1)[0]\n",
    "\n",
    "im_path = env.download_image(example_image_id)\n",
    "image = io.imread(im_path)\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_hierarchy = env.eti_api.get_categories_hierarchy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(categories_hierarchy)):\n",
    "    print(f\"{i}, category: {categories_hierarchy[i]['id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD CATEGORIES NAME AND TYPES TO IMAGES DATAFRAME\n",
    "\n",
    "def create_cat_dict(cat_list):\n",
    "    cat_dict_types = {}\n",
    "    cat_dict_names = {}\n",
    "    for l in cat_list:\n",
    "        if 'type' in l:\n",
    "            cat_dict_types[l['id']] = l['type']\n",
    "        else:\n",
    "            cat_dict_types[l['id']] = 'NoType'\n",
    "        if 'name' in l:\n",
    "            cat_dict_names[l['id']] = l['name']\n",
    "        else:\n",
    "            cat_dict_names[l['id']] = 'NoName'\n",
    "    return cat_dict_types, cat_dict_names\n",
    "\n",
    "\n",
    "\n",
    "def get_weed_subcategory_name_by_subcategory_id(types_ids_list):\n",
    "    types_ids_list = eval(types_ids_list)\n",
    "    print(types_ids_list)\n",
    "    cat_dict_types, cat_dict_names = create_cat_dict(categories_hierarchy[9]['subCategories'])\n",
    "    names_list = []\n",
    "    types_list = []\n",
    "    print(len(types_ids_list))\n",
    "    for i in range(len(types_ids_list)):\n",
    "        print(cat_dict_names[types_ids_list[i]])\n",
    "        names_list.append(cat_dict_names[types_ids_list[i]])\n",
    "        types_list.append(cat_dict_types[types_ids_list[i]])\n",
    "\n",
    "    \n",
    "    \n",
    "    # weed_subcategories = categories_hierarchy[9]['subCategories']\n",
    "    # names_list = []\n",
    "    # for i in range(len(types_ids_list)):\n",
    "    #     for j in range(len(weed_subcategories)):\n",
    "    #         if weed_subcategories[j]['id'] == types_ids_list[i]:\n",
    "    #             names_list.append(weed_subcategories[j]['name'])\n",
    "\n",
    "    # if len(names_list) != len(types_ids_list):\n",
    "        # raise Exception(\"names_list and types_ids_list lengths are different\")\n",
    "    return names_list\n",
    "\n",
    "images_df[images_df['weed_types_ids_list'].apply(get_weed_subcategory_name_by_subcategory_id)]\n",
    "# print(images_df[images_df['weed_types_ids_list'].apply(get_weed_subcategory_name_by_subcategory_id)])\n",
    "# images_df['weed_types_list'] = images_df[images_df['weed_types_ids_list'].apply(get_weed_subcategory_name_by_subcategory_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df = pd.read_csv(\"/mnt/disks/datasets/wide_images/images_df_new_1.csv\")\n",
    "unique_weed_types = np.unique(images_df['weed_types_dict'].explode(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXCLUDED IMAGES FOR CREATING FINAL_DF:\n",
    "# FROM interesting_weed_df: [8980681, 8980665, 7076176, 8980677, 7073428, 8980673, 7077207, 7073971, 8980669]\n",
    "# FROM small_num_of_tags_df_soy : [8190898, 10384238, 6513168, 9182595, 8016877, 8415772, 6767859, 8733629, 9120611, 8730740, 6467322]\n",
    "# FROM small_num_of_tags_df_corn :\n",
    "# excluded_image_ids.extend([8980681, 8980665, 7076176, 8980677, 7073428, 8980673, 7077207, 7073971, 8980669])\n",
    "# excluded_image_ids.extend([8190898, 10384238, 6513168, 9182595, 8016877, 8415772, 6767859, 8733629, 9120611, 8730740, 6467322])\n",
    "# excluded_image_ids.extend([7037805, 6245305, 7836752, 7836449, 7899418, 7836202, 7043002])\n",
    "# excluded_image_ids.extend([6325835, 6325719, 6325835])\n",
    "# excluded_image_ids.extend([5729837, 8724366, 5729837, 5828866, 7652376])\n",
    "# excluded_image_ids.extend([5682996, 5397485, 8718398, 5396859, 8718440, 5161751])\n",
    "# excluded_image_ids.extend([5682996, 5161751, 6264631, 8718440, 8718398])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK RAM USAGE\n",
    "\n",
    "import psutil\n",
    "\n",
    "# Get the system's memory information\n",
    "memory_info = psutil.virtual_memory()\n",
    "# Access the available RAM in bytes\n",
    "available_ram = memory_info.available\n",
    "# Convert bytes to gigabytes (GB)\n",
    "available_ram_gb = available_ram / (1024 ** 3)\n",
    "\n",
    "# Get the memory usage for the current process (kernel)\n",
    "process = psutil.Process()\n",
    "memory_info = process.memory_info()\n",
    "memory_usage_mb = memory_info.rss / 1024 / 1024\n",
    "memory_usage_gb = memory_usage_mb / 1024\n",
    "\n",
    "print(f\"Memory usage: {memory_usage_gb} GB\")\n",
    "\n",
    "print(f\"Available RAM: {available_ram_gb} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE - ADDING ORDERS DATA TO IMAGES DF\n",
    "\n",
    "orders_df = pd.DataFrame({'orders' : [1,2,3,4], 'pass_num' : [1,1,2,2]})\n",
    "images_df = pd.DataFrame({'orders' : [1, 1, 1, 2, 2, 3, 4, 4, 4], 'im_num' : [111, 121, 122, 123, 333, 444,555, 333, 999]})\n",
    "\n",
    "merged_df = images_df.merge(orders_df, on='orders')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from late flights data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTER IMAGES DATAFRAME\n",
    "from datetime import datetime\n",
    "\n",
    "im_df = im_df[(im_df['cameraAngle'] > -95) & (im_df['cameraAngle'] < -85)]\n",
    "im_df = im_df[im_df['deleted'] != True]\n",
    "\n",
    "# im_df['weed_types_ids_list'] = im_df['weed_types_ids_list'].apply(eval)\n",
    "# im_df['uploadDate_time'] = im_df['uploadDate'].apply(datetime.fromtimestamp)\n",
    "# im_df['uploadDate_date'] = im_df['uploadDate_time'].apply(lambda x: x.to_pydatetime().date())\n",
    "\n",
    "# im_df.columns\n",
    "len(im_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "im_df['pass_num_new'] = None\n",
    "im_df['pass_num_new'] = np.where(im_df['fieldID'].isin(early_flights_field_ids), 1, im_df['pass_num_new'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW IMAGES FROM THE DATAFRAME\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# df_to_show = df_for_resolution_lim_checkup[20:].reset_index(drop=True)\n",
    "df_to_show = example_images.reset_index(drop=True)\n",
    "\n",
    "for i in range(len(df_to_show)):\n",
    "    example_image_id = df_to_show['imageID'][i]\n",
    "    # SHOW IMAGES\n",
    "    print(f\"Zoom image id: {example_image_id}\")\n",
    "    image_data = df_to_show[df_to_show['imageID'] == example_image_id].reset_index(drop=True)\n",
    "\n",
    "    # # image_data = df_to_show[df_to_show['imageID'] == example_image_id]\n",
    "    # # matching_wide_image_id = int(image_data.at[0, 'wideImageID'])\n",
    "    # # print(f\"Wide image id: {matching_wide_image_id}\")\n",
    "    # image_num_tags = image_data.at[0, 'num_weed_tags']\n",
    "    # image_num_manual_tags = image_data.at[0, 'weed_manualTagsCount']\n",
    "    # image_num_inference_tags = image_data.at[0, 'weed_inferenceTagsCount']\n",
    "    pass_num = image_data.at[0, 'pass_num']\n",
    "    # image_crop_name = image_data.at[0, 'cropName']\n",
    "    # upload_date = image_data.at[0, 'uploadDate_date']\n",
    "    # weed_types = image_data.at[0, 'weed_types_ids_list']\n",
    "    # # weed_types = eval(image_data.at[0, 'weed_types_ids_list'])\n",
    "    # weed_types = list(map(cat_dict_names.get, weed_types))\n",
    "\n",
    "\n",
    "    im_path = env.download_image(int(example_image_id))\n",
    "    image = io.imread(im_path)\n",
    "\n",
    "    # wide_im_path = env.download_image(int(matching_wide_image_id))\n",
    "    # wide_image = io.imread(wide_im_path)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1)\n",
    "    axes.imshow(image, extent=[0, image.shape[1], 0, image.shape[0]])\n",
    "    # axes[1].imshow(wide_image, extent=[0, wide_image.shape[1], 0, wide_image.shape[0]])\n",
    "\n",
    "\n",
    "    axes.set_xticks([])\n",
    "    axes.set_yticks([])\n",
    "    fig.set_size_inches(20, 10)\n",
    "    plt.suptitle(f\"pass num: {pass_num}\")\n",
    "    # plt.suptitle(f\"Crop Type: {image_crop_name}\\nZoom Image ID: {example_image_id}\\nuploadDate: {upload_date}\\nNum Weed Tags: {image_num_tags}\\nManual tags: {image_num_manual_tags}, Inference tags: {image_num_inference_tags}\\nWeed types: {weed_types}\")\n",
    "    # plt.suptitle(f\"Crop Type: {image_crop_name}\\nZoom Image ID: {example_image_id}, Wide Image ID: {matching_wide_image_id}\\nuploadDate: {upload_date}\\nNum Weed Tags: {image_num_tags}\\nManual tags: {image_num_manual_tags}, Inference tags: {image_num_inference_tags}\\nWeed types: {weed_types}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_df['pass_num'] = [int(eval(im_df['Pass #'][i])['value']) for i in range(len(im_df))]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create grid json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_json_path = \"data/dataloop_jsons/6415975.json\"\n",
    "example_json_path = 'data/dataloop_jsons/example_json_from_itayg.json'\n",
    "with open(example_json_path) as file:\n",
    "    example_data = json.load(file)\n",
    "\n",
    "# example_polygon_coordinates = example_data['annotations'][0]['coordinates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_random_boxes_coords(items_df, image_shape, num_boxes=10, grid_shape=(507, 434)):\n",
    "    grid_coords = get_grid_coords(image_shape)\n",
    "\n",
    "\n",
    "    random_boxes = grid_coords.sample(n=10)\n",
    "\n",
    "    top_left_random_boxes = np.random.choice(top_left_list, size=num_boxes, replace=False)\n",
    "\n",
    "    bottom_right_random_boxes = top_left_random_boxes + np.array(grid_shape)\n",
    "\n",
    "    items_df['top_left'] = np.array(list(map(tuple, top_left_random_boxes)))\n",
    "    items_df['bottom_right'] = np.array(list(map(tuple, bottom_right_random_boxes)))\n",
    "\n",
    "    # np.array(list(zip(top_random_selection, left_random_selection)))\n",
    "    items_df['boxes_coords'] = {'top_left': np.array(list(map(tuple, top_left_random_boxes))),\n",
    "                                'bottom_right': np.array(list(map(tuple, bottom_right_random_boxes)))}\n",
    "    return items_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # example_image_id_from_dataset = items_df['name'][0]\n",
    "    # example_im_path = env.download_image(int(example_image_id_from_dataset))\n",
    "    # example_image = io.imread(example_im_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD TO DATAFRAME IMAGES FROM TTT\n",
    "ttt_images_paths = glob.glob(os.path.join(\"images_to_dataloop_ttt/wide_ttt\", \"*.jpg\"))\n",
    "ttt_images_ids = [int(os.path.basename(p).replace(\".jpg\", \"\")) for p in ttt_images_paths]\n",
    "df_existing_images = weeds_df[weeds_df['imageID'].isin(ttt_images_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZOOM IMAGES THAT DOESNT HAVE WIDE \n",
    "\n",
    "problematic_images_zoom = images_data_new[images_data_new['wideImageID'].isna()]['imageID']\n",
    "wide_checkup = env.eti_api.get_matching_wide_images(list(problematic_images_zoom))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resolution reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLUR IMAGE - BLOCK REDUCE\n",
    "\n",
    "resolution_options = [7, 8, 9, 10]  # mm / pixel\n",
    "\n",
    "\n",
    "random_image_id = int(os.path.basename(np.random.choice(jsons_paths_list)).replace(\".json\", \"\"))\n",
    "random_image_data = images_data[images_data['imageID'] == random_image_id]\n",
    "\n",
    "im_path = env.download_image(random_image_id)\n",
    "original_image = io.imread(im_path)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(24, 8), tight_layout=True, constrained_layout=True)\n",
    "axs = axs.flatten()\n",
    "for i, ax in enumerate(axs):\n",
    "    processed_image = skimage.measure.block_reduce(original_image, (resolution_options[i],resolution_options[i],1), np.mean).astype(np.uint8)\n",
    "    processed_image = resize(processed_image, (original_image.shape[0], original_image.shape[1]), mode='constant', anti_aliasing=False)\n",
    "    ax.imshow(processed_image)\n",
    "    ax.set_title(f\"Block size: {resolution_options[i]}\")\n",
    "    # del upscaled_image\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESOLUTION CALCULATION - TRY. NOT GOOD\n",
    "\n",
    "\n",
    "def get_x_y_px(resolution, new_resolution, fp_x_m, fp_y_m):\n",
    "    x_px = int(resolution/new_resolution) * fp_x_m\n",
    "    y_px = int(resolution/new_resolution) * fp_y_m\n",
    "    return x_px, y_px\n",
    "\n",
    "\n",
    "def get_image_resolution(height, focal_length):\n",
    "    fp_x_m = (height / focal_length) * CCD_X # m\n",
    "    fp_y_m = (height / focal_length) * CCD_Y # m\n",
    "    # total_ground_area = fp_x_m * fp_y_m # m^2\n",
    "    resolution = 0.5*(fp_x_m/IMAGE_X_PX + fp_y_m/IMAGE_Y_PX)*1000 # mm/px\n",
    "    return resolution, fp_x_m, fp_y_m\n",
    "\n",
    "\n",
    "# random_image_id = int(os.path.basename(np.random.choice(jsons_paths_list)).replace(\".json\", \"\"))\n",
    "random_image_id = 9568380\n",
    "random_image_data = images_data[images_data['imageID'] == random_image_id]\n",
    "\n",
    "im_path = env.download_image(random_image_id)\n",
    "original_image = io.imread(im_path)\n",
    "\n",
    "flights_heights_options = np.arange(20, 55, 5)\n",
    "\n",
    "for h in flights_heights_options:\n",
    "    focal_length = random_image_data['focalLength'].values[0]\n",
    "    flight_height = random_image_data['heightAboveGround'].values[0]\n",
    "    image_resolution, fp_x_m, fp_y_m = get_image_resolution(flight_height, focal_length)\n",
    "    new_image_resolution, new_fp_x_m, new_fp_y_m = get_image_resolution(h, focal_length)\n",
    "    print(f\"image_resolution: {image_resolution:.2f}, image_new_resolution:{new_image_resolution:.2f}\")\n",
    "    print(f\"new_fp_x_m: {new_fp_x_m:.2f},new_fp_y_m: {new_fp_y_m:.2f}\")\n",
    "    image_x_px_new, image_y_px_new = get_x_y_px(image_resolution, new_image_resolution)\n",
    "    print(f\"new image shape: ({image_x_px_new, image_y_px_new})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW IMAGES DIFFERENT RESOLUTIONS\n",
    "\n",
    "random_image_id = int(os.path.basename(np.random.choice(jsons_paths_list)).replace(\".json\", \"\"))\n",
    "random_image_data = images_data[images_data['imageID'] == random_image_id]\n",
    "\n",
    "im_path = env.download_image(random_image_id)\n",
    "original_image = io.imread(im_path)\n",
    "\n",
    "num_images = len(resolutions_dict)\n",
    "num_rows = (num_images + 1) // 2  # Calculate the number of rows needed\n",
    "\n",
    "fig, axs = plt.subplots(num_rows, 2, figsize=(8, 8))  # Create subplots\n",
    "\n",
    "for i, height in enumerate(resolutions_dict.keys()):\n",
    "    processed_image = resize(original_image, (resolutions_dict[height][0], resolutions_dict[height][0], 3), anti_aliasing=True)\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    ax = axs[row, col]\n",
    "    ax.imshow(processed_image)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f\"Height: {height}\")\n",
    "\n",
    "# If the number of images is odd, remove the last subplot\n",
    "if num_images % 2 != 0:\n",
    "    axs[num_rows - 1, 1].axis('off')\n",
    "    fig.delaxes(axs[num_rows - 1, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLUR IMAGE BY RESOLUTION\n",
    "\n",
    "random_image_id = int(os.path.basename(np.random.choice(jsons_paths_list)).replace(\".json\", \"\"))\n",
    "random_image_data = images_data[images_data['imageID'] == random_image_id]\n",
    "\n",
    "im_path = env.download_image(random_image_id)\n",
    "original_image = io.imread(im_path)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(24, 8), tight_layout=True, constrained_layout=True)\n",
    "axs = axs.flatten()\n",
    "for i, ax in enumerate(axs):\n",
    "    processed_image = resize(original_image, (resolutions_dict[50][0], resolutions_dict[50][0], 3), anti_aliasing=True)\n",
    "    processed_image = resize(processed_image, (original_image.shape[0], original_image.shape[1]), mode='constant', anti_aliasing=False)\n",
    "    # processed_image = skimage.measure.block_reduce(original_image, (resolution_options[i],resolution_options[i],1), np.mean).astype(np.uint8)\n",
    "    # processed_image = resize(processed_image, (original_image.shape[0], original_image.shape[1]), mode='constant', anti_aliasing=False)\n",
    "    ax.imshow(processed_image)\n",
    "    ax.set_title(f\"Block size: {resolution_options[i]}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISPLAY ONE POLYGON ON DIFFERENT RESOLUTION IMAGES\n",
    "\n",
    "example_image_id = random_image_id\n",
    "# example_image_id = 7843185\n",
    "# example_image_id = 6415975\n",
    "CHOSEN_TAG = 1\n",
    "\n",
    "# example_json_path = \"data/dataloop_jsons/6415975.json\"\n",
    "example_json_path = f\"data/dataloop/annotations_anafa_2023_06_23_resolution_lim_dataset_1_v0/json/{example_image_id}.json\"\n",
    "images_resolutions_paths_list = glob.glob(os.path.join(resized_images_folder, f\"{example_image_id}*.jpg\"))\n",
    "images_resolutions_paths_list = [images_resolutions_paths_list[0], images_resolutions_paths_list[-1]]\n",
    "\n",
    "\n",
    "with open(example_json_path) as file:\n",
    "    example_data = json.load(file)\n",
    "\n",
    "example_polygon_coordinates = example_data['annotations'][0]['coordinates']\n",
    "# im_path = env.download_image(int(example_image_id))\n",
    "\n",
    "x_values = [coord['x'] for coord in example_data['annotations'][CHOSEN_TAG]['coordinates'][0]]\n",
    "y_values = [coord['y'] for coord in example_data['annotations'][CHOSEN_TAG]['coordinates'][0]]\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "num_images = len(images_resolutions_paths_list)\n",
    "num_rows = num_images // 2  # Divide and round up\n",
    "num_cols = min(num_images, 2)\n",
    "\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(10, 10))\n",
    "\n",
    "axs = axs.flatten()\n",
    "for i, ax in enumerate(axs):\n",
    "\n",
    "    image = io.imread(images_resolutions_paths_list[i])\n",
    "    polygon = patches.Polygon(list(zip(x_values, y_values)), closed=True, fill=None, edgecolor='aquamarine')\n",
    "\n",
    "    ax.imshow(image)\n",
    "    ax.add_patch(polygon)\n",
    "\n",
    "    ax.set_xlim(min(x_values)-100, max(x_values)+100)\n",
    "    ax.set_ylim(min(y_values)-100, max(y_values)+100)\n",
    "\n",
    "    subtitle = images_resolutions_paths_list[i].replace(f\"{example_image_id}_\", \"\")\n",
    "    ax.set_title(f\"image: {os.path.basename(subtitle)}\")\n",
    "\n",
    "fig.suptitle(f\"Image ID: {example_image_id}\", y=0.8)\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISPLAY ALL DL POLYGONS ON THE IMAGE\n",
    "\n",
    "# example_image_id = 6044767\n",
    "example_image_id = 6415975\n",
    "\n",
    "# example_json_path = \"data/dataloop_jsons/6415975.json\"\n",
    "example_json_path = f\"data/dataloop/annotations_anafa_2023_06_23_resolution_lim_dataset_1_v0/json/{example_image_id}.json\"\n",
    "\n",
    "with open(example_json_path) as file:\n",
    "    example_data = json.load(file)\n",
    "\n",
    "example_polygon_coordinates = example_data['annotations'][0]['coordinates']\n",
    "im_path = env.download_image(int(example_image_id))\n",
    "image = io.imread(im_path)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "num_images = len(example_data['annotations'])\n",
    "num_rows = num_images // 2  # Divide and round up\n",
    "num_cols = min(num_images, 2)\n",
    "\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(10, 10))\n",
    "\n",
    "axs = axs.flatten()\n",
    "for i, ax in enumerate(axs):\n",
    "\n",
    "    x_values = [coord['x'] for coord in example_data['annotations'][i]['coordinates'][0]]\n",
    "    y_values = [coord['y'] for coord in example_data['annotations'][i]['coordinates'][0]]\n",
    "    polygon = patches.Polygon(list(zip(x_values, y_values)), closed=True, fill=None, edgecolor='aquamarine')\n",
    "\n",
    "    ax.imshow(image)\n",
    "    ax.add_patch(polygon)\n",
    "\n",
    "    ax.set_xlim(min(x_values)-100, max(x_values)+100)\n",
    "    ax.set_ylim(min(y_values)-100, max(y_values)+100)\n",
    "\n",
    "    ax.set_title(f\"tag: {example_data['annotations'][i]['label']}\")\n",
    "\n",
    "fig.suptitle(f\"Image ID: {example_image_id}\")\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLUR IMAGE BY RESOLUTION\n",
    "\n",
    "random_image_id = int(os.path.basename(np.random.choice(jsons_paths_list)).replace(\".json\", \"\"))\n",
    "random_image_data = images_data[images_data['imageID'] == random_image_id]\n",
    "\n",
    "im_path = env.download_image(random_image_id)\n",
    "original_image = io.imread(im_path)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(24, 8), tight_layout=True, constrained_layout=True)\n",
    "axs = axs.flatten()\n",
    "for i, ax in enumerate(axs):\n",
    "    processed_image = resize(original_image, (resolutions_dict[50][0], resolutions_dict[50][0], 3), anti_aliasing=True)\n",
    "    processed_image = resize(processed_image, (original_image.shape[0], original_image.shape[1]), mode='constant', anti_aliasing=False)\n",
    "    # processed_image = skimage.measure.block_reduce(original_image, (resolution_options[i],resolution_options[i],1), np.mean).astype(np.uint8)\n",
    "    # processed_image = resize(processed_image, (original_image.shape[0], original_image.shape[1]), mode='constant', anti_aliasing=False)\n",
    "    ax.imshow(processed_image)\n",
    "    ax.set_title(f\"Block size: {resolution_options[i]}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_image_id = example_image_data['wideImageID']\n",
    "wide_im_path = env.download_image(int(wide_image_id))\n",
    "wide_image = io.imread(wide_im_path)\n",
    "wide_image_data = env.eti_api.get_images_data([wide_image_id])\n",
    "\n",
    "wide_image_shape = wide_image.shape[0], wide_image.shape[1]\n",
    "wide_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(24, 8), tight_layout=True, constrained_layout=True)\n",
    "axs = axs.flatten()\n",
    "for i, ax in enumerate(axs):\n",
    "    processed_image = resize(original_image, (resolutions_dict[50][0], resolutions_dict[50][0], 3), anti_aliasing=True)\n",
    "    processed_image = resize(processed_image, (original_image.shape[0], original_image.shape[1]), mode='constant', anti_aliasing=False)\n",
    "    # processed_image = skimage.measure.block_reduce(original_image, (resolution_options[i],resolution_options[i],1), np.mean).astype(np.uint8)\n",
    "    # processed_image = resize(processed_image, (original_image.shape[0], original_image.shape[1]), mode='constant', anti_aliasing=False)\n",
    "    ax.imshow(processed_image)\n",
    "    ax.set_title(f\"Block size: {resolution_options[i]}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESIZE IMAGES AND SAVE - FROM IMAGES SIZE LIST\n",
    "\n",
    "resized_images_folder = os.path.join(\"images\", \"resized_images\")\n",
    "os.makedirs(resized_images_folder, exist_ok=True)\n",
    "\n",
    "# random_image_id = int(os.path.basename(np.random.choice(jsons_paths_list)).replace(\".json\", \"\"))\n",
    "# random_image_id = 6415975\n",
    "# random_image_data = images_data[images_data['imageID'] == random_image_id]\n",
    "\n",
    "random_image_id = example_image_id\n",
    "\n",
    "im_path = env.download_image(random_image_id)\n",
    "original_image = io.imread(im_path)\n",
    "\n",
    "for i in range(len(ax_0)):\n",
    "    processed_image_name = f\"{random_image_id}_{i}_try4.jpg\"\n",
    "    processed_image_path = os.path.join(resized_images_folder, processed_image_name)\n",
    "    processed_image = resize(original_image, (ax_1[i], ax_0[i], 3), anti_aliasing=True)\n",
    "    processed_image = resize(processed_image, (original_image.shape[0], original_image.shape[1]), mode='constant', anti_aliasing=False)\n",
    "\n",
    "    io.imsave(processed_image_path, processed_image)\n",
    "    processed_image = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESIZE IMAGES AND SAVE - FROM RESOLUTION DICT\n",
    "\n",
    "resized_images_folder = os.path.join(\"images\", \"resized_images\")\n",
    "os.makedirs(resized_images_folder, exist_ok=True)\n",
    "\n",
    "random_image_id = int(os.path.basename(np.random.choice(jsons_paths_list)).replace(\".json\", \"\"))\n",
    "# random_image_id = 6415975\n",
    "random_image_data = images_data[images_data['imageID'] == random_image_id]\n",
    "\n",
    "im_path = env.download_image(random_image_id)\n",
    "original_image = io.imread(im_path)\n",
    "\n",
    "for i, height in enumerate(resolutions_dict.keys()):\n",
    "    processed_image_name = f\"{random_image_id}_h_{height}_try.jpg\"\n",
    "    processed_image_path = os.path.join(resized_images_folder, processed_image_name)\n",
    "    processed_image = resize(original_image, (resolutions_dict[height][1], resolutions_dict[height][0], 3), anti_aliasing=True)\n",
    "    processed_image = resize(processed_image, (original_image.shape[0], original_image.shape[1]), mode='constant', anti_aliasing=False)\n",
    "\n",
    "    io.imsave(processed_image_path, processed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_steps = 5\n",
    "# step_size = (wide_image_resolution - zoom_image_resolution) / (num_steps - 1)\n",
    "# resolutions_list = np.arange(zoom_image_resolution, wide_image_resolution + 2*step_size, step_size)\n",
    "\n",
    "# resolutions_list = resolution_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE RESOLUTION DICTIONARY BY ZOOM IMAGE SIZE\n",
    "\n",
    "# GET WIDE IMAGE SHAPE\n",
    "# example_image_id = 5246509\n",
    "# example_image_id = 6415975\n",
    "zoom_im_path = env.download_image(int(example_image_id))\n",
    "\n",
    "zoom_image = io.imread(zoom_im_path)\n",
    "wide_im_id = env.eti_api.get_matching_wide_images([example_image_id])[0]\n",
    "wide_im_path = env.download_image(wide_im_id)\n",
    "wide_image = io.imread(wide_im_path)\n",
    "wide_image_shape = wide_image.shape[:-1]\n",
    "\n",
    "# grid_shape = (wide_image_shape[1]//7, wide_image_shape[0]//8)\n",
    "num_steps = 5\n",
    "\n",
    "step_size_0 = (wide_image_shape[0] - wide_image_shape[0]//7) / (num_steps - 1)\n",
    "step_size_1 = (wide_image_shape[1] - wide_image_shape[1]//8) / (num_steps - 1)\n",
    "\n",
    "ax_0 = np.arange(wide_image_shape[0]//7, wide_image_shape[0], step_size_0).astype(int)\n",
    "ax_1 = np.arange(wide_image_shape[1]//8, wide_image_shape[1], step_size_1).astype(int)\n",
    "\n",
    "del zoom_image, wide_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read dataloop annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOWNLOAD ANNOTATIONS - POLYGONS\n",
    "\n",
    "DATASET_NAME = \"\"\n",
    "TASK_NAME = 'anafa_2023_06_23_resolution_lim_first_task_01'\n",
    "VERSION = 0\n",
    "\n",
    "dataloop_local_data_dir = os.path.join(DATA_DIR, f\"dataloop\")\n",
    "annotation_local_path = os.path.join(dataloop_local_data_dir, f\"annotations_{DATASET_NAME}_task_{TASK_NAME}_v{VERSION}\")\n",
    "\n",
    "jsons_folder = os.path.join(annotation_local_path, \"json\")\n",
    "jsons_paths_list = glob.glob(os.path.join(jsons_folder, \"*.json\"))\n",
    "\n",
    "polygons_task = project.tasks.get(task_name=TASK_NAME)\n",
    "# task.\n",
    "\n",
    "\n",
    "dataset = project.datasets.get(dataset_name=DATASET_NAME)\n",
    "# # dataset.download(local_path=dataloop_local_data_dir,\n",
    "# #                  annotation_options=dl.VIEW_ANNOTATION_OPTIONS_JSON)\n",
    "dataset.download_annotations(local_path=annotation_local_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE - DISPLAY ONE IMAGE POINTS TAGS\n",
    "\n",
    "example_image_id = 9638024\n",
    "example_im_path = env.download_image(int(image_id))\n",
    "example_image = io.imread(im_path)\n",
    "original_image_width = example_image.shape[1]\n",
    "original_image_height = example_image.shape[0]\n",
    "\n",
    "# image_id = points_task_image_ids_list[11]\n",
    "# image_id = 9638024\n",
    "image_id = 9445268\n",
    "points_tags_json = [path for path in points_jsons_paths_list if str(image_id) in path][0]\n",
    "polygons_tags_json = [path for path in polygons_jsons_paths_list if str(image_id) in path][0]\n",
    "\n",
    "\n",
    "with open(points_tags_json) as file:\n",
    "    points_json_data = json.load(file)\n",
    "\n",
    "im_path = env.download_image(int(image_id))\n",
    "image = io.imread(im_path)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(image)\n",
    "\n",
    "\n",
    "for i in range(len(points_json_data['annotations'])):\n",
    "    width = points_json_data['metadata']['system']['width']\n",
    "    height = points_json_data['metadata']['system']['height']\n",
    "\n",
    "    width_factor = original_image_width / width\n",
    "    height_factor = original_image_height / height\n",
    "\n",
    "    x_value = int(points_json_data['annotations'][i]['coordinates']['x']) * width_factor\n",
    "    y_value = int(points_json_data['annotations'][i]['coordinates']['y']) * height_factor\n",
    "\n",
    "    # print(f\"x: {points_json_data['annotations'][i]['coordinates']['x'], x_value}\")\n",
    "    # print(f\"y: {points_json_data['annotations'][i]['coordinates']['y'], y_value}\")\n",
    "    \n",
    "    ax.plot(x_value, y_value, 'mo')\n",
    "    ax.set_xlim(1800, 2100)\n",
    "    ax.set_ylim(2800, 2500)\n",
    "\n",
    "    ax.set_title(f\"image: {im_path}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE - DISPLAY ONE IMAGE POLYGONS TAGS\n",
    "\n",
    "# image_id = points_task_image_ids_list[9]\n",
    "\n",
    "image_id = 9638024\n",
    "\n",
    "points_tags_json = [path for path in points_jsons_paths_list if str(image_id) in path][0]\n",
    "polygons_tags_json = [path for path in polygons_jsons_paths_list if str(image_id) in path][0]\n",
    "\n",
    "\n",
    "with open(polygons_tags_json) as file:\n",
    "    polygons_json_data = json.load(file)\n",
    "\n",
    "\n",
    "im_path = env.download_image(int(image_id))\n",
    "image = io.imread(im_path)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(image)\n",
    "\n",
    "for i in range(len(polygons_json_data['annotations'])):\n",
    "\n",
    "    x_values = [coord['x'] for coord in polygons_json_data['annotations'][i]['coordinates'][0]]\n",
    "    y_values = [coord['y'] for coord in polygons_json_data['annotations'][i]['coordinates'][0]]\n",
    "    polygon = patches.Polygon(list(zip(x_values, y_values)), closed=True, fill=None, edgecolor='aquamarine')\n",
    "\n",
    "    ax.add_patch(polygon)\n",
    "\n",
    "    # ax.set_xlim(0, image.shape[1])\n",
    "    # ax.set_ylim(0, image.shape[0])\n",
    "    # ax.set_ylim(image.shape[0], 0)\n",
    "    # ax.set_xlim(0, 500)\n",
    "    # ax.set_ylim(3500, 3800)\n",
    "\n",
    "\n",
    "    ax.set_title(f\"image: {im_path}\")\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read_dataloop_annotations_resolution_5_res_20_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_polygons_df_example(polygons_list, image_id):\n",
    "\n",
    "    im_path = env.download_image(int(image_id))\n",
    "    image = io.imread(im_path)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "\n",
    "    polygons_df = pd.DataFrame()\n",
    "    polygons_df['overlapping_polygons_indexes'] = find_overlapping_polygons_indexes(polygons_list)\n",
    "    example_overlapping_polygons_indexes = polygons_df['overlapping_polygons_indexes'][0]\n",
    "    example_overlapping_polygons = list(map(lambda i: polygons_list[i], example_overlapping_polygons_indexes))\n",
    "    poly_intersection = get_polygons_intersection(example_overlapping_polygons)\n",
    "    poly_union = get_polygons_union(example_overlapping_polygons)\n",
    "    poly_iou = get_polygons_iou(example_overlapping_polygons)\n",
    "    poly_box = get_polygons_box(poly_union, dilation = 0)\n",
    "\n",
    "    p1_patch = PolygonPatch(np.array(poly_intersection.exterior.coords), facecolor='none', edgecolor='cornflowerblue', linewidth=2)\n",
    "    p2_patch = PolygonPatch(np.array(poly_union.exterior.coords), facecolor='none', edgecolor='orange', linewidth=2)\n",
    "    p4_patch = PolygonPatch(np.array(poly_box.exterior.coords), facecolor='none', edgecolor='springgreen', linewidth=2)\n",
    "\n",
    "\n",
    "    minx, miny, maxx, maxy = poly_union.bounds\n",
    "\n",
    "    # p3_patch = PolygonPatch(np.array(poly_iou.exterior.coords), facecolor='none', edgecolor='green', linewidth=2)\n",
    "    # minx, miny, maxx, maxy = poly_box\n",
    "    # width = maxx - minx\n",
    "    # height = maxy - miny\n",
    "    # p4_patch = Rectangle((minx, miny), width, height, facecolor='none', edgecolor='springgreen', linewidth=2)\n",
    "\n",
    "\n",
    "    plt.gca().add_patch(p1_patch)\n",
    "    plt.gca().add_patch(p2_patch)\n",
    "    # plt.gca().add_patch(p3_patch)\n",
    "    plt.gca().add_patch(p4_patch)\n",
    "\n",
    "    text_x, text_y = minx, miny-50\n",
    "    plt.text(text_x, text_y, \"intersection\", fontsize=12, color='cornflowerblue', ha='center', va='center')\n",
    "    plt.text(text_x, text_y+20, \"union\", fontsize=12, color='orange', ha='center', va='center')\n",
    "    # plt.text(text_x, text_y, \"intersection\", fontsize=12, color='cornflowerblue', ha='center', va='center')\n",
    "\n",
    "\n",
    "\n",
    "    plt.xlim(minx-100, maxx+100)\n",
    "    plt.ylim(maxy+100, miny-100)\n",
    "\n",
    "    plt.savefig('images/output_image_with_polygons_8.jpg')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # intersection_patch = PolygonPatch(np.array(poly_intersection.exterior.coords), facecolor='none', edgecolor='cornflowerblue', linewidth=2)\n",
    "    # union_patch = PolygonPatch(np.array(poly_union.exterior.coords), facecolor='none', edgecolor='orange', linewidth=2)\n",
    "    # box_patch = PolygonPatch(np.array(poly_box.exterior.coords), facecolor='none', edgecolor='springgreen', linewidth=2)\n",
    "\n",
    "    # minx, miny, maxx, maxy = poly_union.bounds\n",
    "\n",
    "    # plt.gca().add_patch(intersection_patch)\n",
    "    # plt.gca().add_patch(union_patch)\n",
    "    # plt.gca().add_patch(box_patch)\n",
    "\n",
    "    # text_x, text_y = minx, miny-50\n",
    "    # plt.text(text_x, text_y, \"intersection\", fontsize=12, color='cornflowerblue', ha='center', va='center')\n",
    "    # plt.text(text_x, text_y+20, \"union\", fontsize=12, color='orange', ha='center', va='center')\n",
    "    # plt.text(f\"Image {image_id}, IOU: {polygons_df['poly_iou']}\")\n",
    "\n",
    "    # # plt.xlim(minx-100, maxx+100)\n",
    "    # # plt.ylim(maxy+100, miny-100)\n",
    "\n",
    "    # image_with_polygons_path = f'images/output_image_with_polygons_{image_with_polygons_path}_8.jpg'\n",
    "    # plt.savefig(image_with_polygons_path)\n",
    "    # plt.close()\n",
    "    # print(f\"Saved image {image_with_polygons_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polygons_intersection(overlapping_polygons_list):\n",
    "    overlapping_polygons_list = reduce_contained_polygons(overlapping_polygons_list)\n",
    "\n",
    "    intersection_polygon = reduce(lambda x, y: x.intersection(y), overlapping_polygons_list)\n",
    "\n",
    "    # intersection_polygons_list = []\n",
    "    # while True:\n",
    "    #     if len(intersection_polygons_list) < 1:\n",
    "    #         intersection_polygons_list = overlapping_polygons_list.copy()\n",
    "    #         break\n",
    "    #     elif len(intersection_polygons_list) == 1:\n",
    "    #         break\n",
    "    #     else:\n",
    "    #         overlapping_polygons_list = intersection_polygons_list.copy()\n",
    "    #         intersection_polygons_list = []\n",
    "    #     for i in range(1, len(overlapping_polygons_list)):\n",
    "    #         intersection_polygons_list.append(overlapping_polygons_list[0].intersection(overlapping_polygons_list[i]))\n",
    "\n",
    "    return intersection_polygon\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # for i in range(len(overlapping_polygons_list)):\n",
    "    #     for j in range(i+1, len(overlapping_polygons_list)):\n",
    "    #         intersection_polygons_list.append(overlapping_polygons_list[i].intersection(overlapping_polygons_list[j]))\n",
    "    # if len(intersection_polygons_list)>1:\n",
    "    #     return get_polygons_intersection(intersection_polygons_list)\n",
    "    # else:\n",
    "    #     return intersection_polygons_list[0]\n",
    "\n",
    "\n",
    "def get_polygons_union(overlapping_polygons_list):\n",
    "    union_polygon = reduce(lambda x, y: x.union(y), overlapping_polygons_list)\n",
    "    return union_polygon\n",
    "\n",
    "\n",
    "\n",
    "    # union_polygons_list = []\n",
    "    # for i in range(len(overlapping_polygons_list)):\n",
    "    #     for j in range(i+1, len(overlapping_polygons_list)):\n",
    "    #         union_polygons_list.append(overlapping_polygons_list[i].union(overlapping_polygons_list[j]))\n",
    "    # if len(union_polygons_list)>1:\n",
    "    #     return get_polygons_intersection(union_polygons_list)\n",
    "    # else:\n",
    "    #     return union_polygons_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resolution limitation exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE - DISPLAY ONE IMAGE TAGS - ONE POINT\n",
    "\n",
    "example_image_id = 5233797\n",
    "example_im_path = env.download_image(int(example_image_id))\n",
    "example_image = io.imread(example_im_path)\n",
    "original_image_width = example_image.shape[1]\n",
    "original_image_height = example_image.shape[0]\n",
    "\n",
    "# image_id = points_task_image_ids_list[15] \n",
    "image_id = 5852565\n",
    "# image_id = 6580458\n",
    "# image_id = 9445268\n",
    "points_tags_json = [path for path in points_jsons_paths_list if str(image_id) in path][0]\n",
    "polygons_tags_json = [path for path in polygons_jsons_paths_list if str(image_id) in path][0]\n",
    "\n",
    "\n",
    "im_path = env.download_image(int(image_id))\n",
    "image = io.imread(im_path)\n",
    "\n",
    "\n",
    "with open(points_tags_json) as file:\n",
    "    points_json_data = json.load(file)\n",
    "\n",
    "with open(polygons_tags_json) as file:\n",
    "    polygons_json_data = json.load(file)\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "\n",
    "ax.imshow(image)\n",
    "\n",
    "shapely_polygons = []\n",
    "\n",
    "# DRAW POLYGONS\n",
    "for i in range(len(polygons_json_data['annotations'])):\n",
    "    x_values = [coord['x'] for coord in polygons_json_data['annotations'][i]['coordinates'][0]]\n",
    "    y_values = [coord['y'] for coord in polygons_json_data['annotations'][i]['coordinates'][0]]\n",
    "    polygon = patches.Polygon(list(zip(x_values, y_values)), closed=True, fill=None, edgecolor='aquamarine')\n",
    "    shapely_polygons.append(Polygon(list(zip(x_values, y_values))))\n",
    "    ax.add_patch(polygon)\n",
    "    ax.set_title(f\"image: {im_path}\")\n",
    "\n",
    "\n",
    "# DRAW POINTS\n",
    "for i in range(len(points_json_data['annotations'])):\n",
    "    width = points_json_data['metadata']['system']['width']\n",
    "    height = points_json_data['metadata']['system']['height']\n",
    "\n",
    "    width_factor = original_image_width / width\n",
    "    height_factor = original_image_height / height\n",
    "\n",
    "    x_value = int(points_json_data['annotations'][i]['coordinates']['x']) * width_factor\n",
    "    y_value = int(points_json_data['annotations'][i]['coordinates']['y']) * height_factor\n",
    "\n",
    "    shapely_point = Point(x_value, y_value)\n",
    "    print(shapely_point)\n",
    "\n",
    "    is_inside = np.any([poly.contains(shapely_point) for poly in shapely_polygons])\n",
    "    if is_inside:\n",
    "        point_color = 'mo'\n",
    "    else:\n",
    "        point_color = 'ro'\n",
    "\n",
    "    ax.plot(x_value, y_value, point_color)\n",
    "\n",
    "    ax.set_xlim(0, 400)\n",
    "    ax.set_ylim(3750, 3500)\n",
    "    # ax.set_xlim(1800, 2100)\n",
    "    # ax.set_ylim(2800, 2500)\n",
    "\n",
    "\n",
    "    ax.set_title(f\"image: {im_path}. {len(points_json_data['annotations'])} point tags\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read DL annotations infestation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_points_to_boxes_old(boxes, labels):\n",
    "    for i, box_row in boxes.iterrows():\n",
    "        pt_list = []\n",
    "        for j, label_row in labels.iterrows():\n",
    "            x_value = int(label_row['coordinates']['x'])\n",
    "            y_value = int(label_row['coordinates']['y'])\n",
    "            shapely_point = Point(x_value, y_value)\n",
    "            is_inside = box_row['box_poly'].contains(shapely_point)\n",
    "            if is_inside:\n",
    "                pt_list.append(shapely_point)\n",
    "        boxes.at[i, \"fitting_points\"] = str(pt_list)\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_indexes = box_df['fitting_points_indexes']\n",
    "# points_indexes = boxes['fitting_points_indexes'][0]\n",
    "box_labels = labels.iloc[points_indexes]\n",
    "most_common_label = labels.iloc[points_indexes]['label'].value_counts().idxmax()\n",
    "box_labels[box_labels['label'].str.contains(r'Infestation|No')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.iloc[infestation_rows]['label'].value_counts().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_infestation_avg(box_labels):\n",
    "     infestation_dict = {\n",
    "         f\"Infestation.Up_to_10%\": 5,\n",
    "         f\"Infestation.10%-25%\": 17.5,\n",
    "         f\"Infestation.25%-50%\": 37.5,\n",
    "         f\"Infestation.50%-75%\": 65.5,\n",
    "         f\"Infestation.above_75%\": 87.5\n",
    "     }\n",
    "     labels_numbers = box_labels.replace(infestation_dict)\n",
    "     return labels_numbers.mean()\n",
    "\n",
    "def get_box_label_and_infestation_avg(box_df, labels):\n",
    "    points_indexes = box_df['fitting_points_indexes']\n",
    "    box_labels = labels.iloc[points_indexes]\n",
    "\n",
    "    infestation_rows = box_labels[box_labels['label'].str.contains(\"Infestation\")].index\n",
    "    no_weeds_rows = box_labels[box_labels['label'].str.contains(\"No\")].index\n",
    "\n",
    "    box_final_label = labels.iloc[infestation_rows]['label'].value_counts().idxmax()\n",
    "    votes = labels.iloc[infestation_rows]['label'].value_counts().max()\n",
    "    \n",
    "    if len(infestation_rows) > 0:\n",
    "        infestation_avarage = get_infestation_avg(labels.iloc[infestation_rows]['label'])\n",
    "    else:\n",
    "        infestation_avarage = 0\n",
    "    return box_final_label, infestation_avarage, votes\n",
    "\n",
    "boxes[\"box_final_label\"] = None\n",
    "boxes[\"infestation_avarage\"] = None\n",
    "for i, box_row in boxes.iterrows():\n",
    "    box_final_label, infestation_avarage, votes = get_box_label_and_infestation_avg(box_row, labels)\n",
    "    boxes.at[i, \"box_final_label\"] = box_final_label\n",
    "    boxes.at[i, \"infestation_avarage\"] = infestation_avarage\n",
    "    boxes.at[i, \"votes\"] = votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_infestation_avg(box_labels):\n",
    "     infestation_dict = {\n",
    "         f\"Infestation.Up_to_10%\": 5,\n",
    "         f\"Infestation.10%-25%\": 17.5,\n",
    "         f\"Infestation.25%-50%\": 37.5,\n",
    "         f\"Infestation.50%-75%\": 65.5,\n",
    "         f\"Infestation.above_75%\": 87.5\n",
    "     }\n",
    "     labels_numbers = box_labels.replace(infestation_dict)\n",
    "     return labels_numbers.mean()\n",
    "\n",
    "def get_box_label_and_infestation_avg(box_df, labels):\n",
    "    points_indexes = box_df['fitting_points_indexes']\n",
    "    box_labels = labels.iloc[points_indexes]\n",
    "\n",
    "    infestation_rows = box_labels[box_labels['label'].str.contains(\"Infestation\")].index\n",
    "    no_weeds_rows = box_labels[box_labels['label'].str.contains(\"No\")].index\n",
    "\n",
    "    if len(no_weeds_rows) > len(infestation_rows):\n",
    "        box_final_label = labels.iloc[infestation_rows]['label'].value_counts().idxmax()\n",
    "        votes = labels.iloc[infestation_rows]['label'].value_counts().max()\n",
    "        if len(infestation_rows) > 0:\n",
    "            infestation_avarage = get_infestation_avg(labels.iloc[infestation_rows]['label'])\n",
    "        else:\n",
    "            infestation_avarage = 0\n",
    "    elif len(infestation_rows) > 0:\n",
    "        box_final_label = labels.iloc[infestation_rows]['label'].value_counts().idxmax()\n",
    "        print(f\"infestation label: {box_final_label}\")\n",
    "        infestation_avarage = get_infestation_avg(labels.iloc[infestation_rows]['label'])\n",
    "        votes = labels.iloc[infestation_rows]['label'].value_counts().max()\n",
    "    else:\n",
    "        raise Exception(f\"Problem whit labels in image id: {im_id}\")\n",
    "\n",
    "    return box_final_label, infestation_avarage, votes\n",
    "\n",
    "boxes[\"box_final_label\"] = None\n",
    "boxes[\"infestation_avarage\"] = None\n",
    "for i, box_row in boxes.iterrows():\n",
    "    box_final_label, infestation_avarage = get_box_label_and_infestation_avg(box_row, labels)\n",
    "    boxes.at[i, \"box_final_label\"] = box_final_label\n",
    "    boxes.at[i, \"infestation_avarage\"] = infestation_avarage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_box_label_and_infestation_avg(box_df, labels):\n",
    "    points_indexes = box_df['fitting_points_indexes']\n",
    "    box_labels = labels.iloc[points_indexes]\n",
    "\n",
    "    infestation_rows = box_labels[box_labels['label'].str.contains(\"Infestation\")].index\n",
    "    no_weeds_rows = box_labels[box_labels['label'].str.contains(\"No\")].index\n",
    "\n",
    "    if len(infestation_rows) > 0:\n",
    "        infestation_avarage = get_infestation_avg(labels.iloc[infestation_rows]['label'])\n",
    "        box_final_label = labels.iloc[infestation_rows]['label'].value_counts().idxmax()\n",
    "        votes = labels.iloc[infestation_rows]['label'].value_counts().max()\n",
    "    else:\n",
    "        infestation_avarage = 0\n",
    "        box_final_label = labels.iloc[no_weeds_rows]['label'].value_counts().idxmax()\n",
    "        votes = labels.iloc[no_weeds_rows]['label'].value_counts().max()\n",
    "    return box_final_label, infestation_avarage, votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"args\": [\n",
    "    // \"--order_ids=[405497, 404108]\",\n",
    "    \"--wide_image_ids=[9134832, 8722161]\",\n",
    "    // \"--wide_image_ids=[8484421, 7876108, 4956894, 6859096, 7014238, 7490734, 7712145, 8722161, 9134832]\",\n",
    "    // \"--wide_image_ids=[8722161, 9134832]\",\n",
    "    // \"--zom_image_ids=[8471755, 7875316]\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def choose_canopy_map(index_canopy_map, hsv_canopy_map):\n",
    "#     hsv_canopy_percent, canopy_index_percent = calculate_canopy_percentage(index_canopy_map, hsv_canopy_map)\n",
    "\n",
    "#     return\n",
    "\n",
    "\n",
    "# def save_histograms(hsv_canopy_percent_list, canopy_index_percent_list, dir=\"data\"):\n",
    "#     data_lists = {\"hsv_percent_list\": hsv_canopy_percent_list,\n",
    "#                   \"index_percent_list\": canopy_index_percent_list}\n",
    "\n",
    "#     fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "#     for i in range(len(data_lists)):\n",
    "#         data = data_lists[list(data_lists.keys())[i]]\n",
    "#         axes[i].hist(data, bins=20, color='lightseagreen', alpha=0.7)\n",
    "#         axes[i].set_xlabel('Canopy coverage percent')\n",
    "#         axes[i].set_ylabel('Frequency')\n",
    "#         axes[i].set_title(list(data_lists.keys())[i].replace(\"_list\", \"\"))\n",
    "#     plt.tight_layout()\n",
    "#     current_datetime = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "#     plt.savefig(os.path.join(dir, f'side_by_side_histograms_{current_datetime}.jpg'))\n",
    "#     print('h')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
